{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanAggregator(nn.Module):\n",
    "    \"\"\"\n",
    "    Aggregates a node's embeddings using mean of neighbors' embeddings\n",
    "    \"\"\"\n",
    "    def __init__(self, features, cuda=False, gcn=False): \n",
    "        \"\"\"\n",
    "        Initializes the aggregator for a specific graph.\n",
    "\n",
    "        features -- function mapping LongTensor of node ids to FloatTensor of feature values.\n",
    "        cuda -- whether to use GPU\n",
    "        gcn --- whether to perform concatenation GraphSAGE-style, or add self-loops GCN-style\n",
    "        \"\"\"\n",
    "\n",
    "        super(MeanAggregator, self).__init__()\n",
    "\n",
    "        self.features = features\n",
    "        self.cuda = cuda\n",
    "        self.gcn = gcn\n",
    "        \n",
    "    def forward(self, nodes, to_neighs, num_sample=10):\n",
    "        \"\"\"\n",
    "        nodes --- list of nodes in a batch\n",
    "        to_neighs --- list of sets, each set is the set of neighbors for node in batch\n",
    "        num_sample --- number of neighbors to sample. No sampling if None.\n",
    "        \"\"\"\n",
    "        # sample\n",
    "        _set = set # Local pointers to functions (speed hack)\n",
    "        if not num_sample is None:\n",
    "            _sample = random.sample\n",
    "            samp_neighs = [_set(_sample(to_neigh, \n",
    "                            num_sample,\n",
    "                            )) if len(to_neigh) >= num_sample else to_neigh for to_neigh in to_neighs]\n",
    "        else:\n",
    "            samp_neighs = to_neighs\n",
    "        # gcn: self-loop, if not then cat\n",
    "        if self.gcn:\n",
    "            samp_neighs = [samp_neigh + set([nodes[i]]) for i, samp_neigh in enumerate(samp_neighs)]\n",
    "        # mask: adj matrix after sampling\n",
    "        unique_nodes_list = list(set.union(*samp_neighs))\n",
    "        unique_nodes = {n:i for i,n in enumerate(unique_nodes_list)}\n",
    "        mask = Variable(torch.zeros(len(samp_neighs), len(unique_nodes)))\n",
    "        column_indices = [unique_nodes[n] for samp_neigh in samp_neighs for n in samp_neigh]   \n",
    "        row_indices = [i for i in range(len(samp_neighs)) for j in range(len(samp_neighs[i]))]\n",
    "        mask[row_indices, column_indices] = 1\n",
    "        \n",
    "        if self.cuda:\n",
    "            mask = mask.cuda()\n",
    "        # normalize mask\n",
    "        num_neigh = mask.sum(1, keepdim=True)\n",
    "        mask = mask.div(num_neigh)\n",
    "        # sampled features\n",
    "        if self.cuda:\n",
    "            embed_matrix = self.features(torch.LongTensor(unique_nodes_list).cuda())\n",
    "        else:\n",
    "            embed_matrix = self.features(torch.LongTensor(unique_nodes_list))\n",
    "        # mean aggregation\n",
    "        to_feats = mask.mm(embed_matrix)\n",
    "        return to_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1}, {2}, {3}, {1}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"sample num_sample neighbors\"\"\"\n",
    "# if num_neign >= num_sample, sample num_sample neighbors\n",
    "# else, keep all neighbors\n",
    "to_neighs = [set([1]), set([2, 3]), set([1, 3]), set([1, 2])]\n",
    "num_sample = 1\n",
    "samp_neighs = [set(random.sample(to_neigh, num_sample)) \n",
    "               if len(to_neigh) >= num_sample else to_neigh for to_neigh in to_neighs]\n",
    "print(samp_neighs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1}, {2}, {3}, {1}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"gcn: self-loop\"\"\"\n",
    "gcn = False\n",
    "if gcn:\n",
    "    samp_neighs = [set(list(samp_neigh) + [i]) for i, samp_neigh in enumerate(samp_neighs) ]\n",
    "print(samp_neighs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[0, 1, 2, 0]\n",
      "[0, 1, 2, 3]\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# union all sampled neighbors\n",
    "unique_nodes_list = list(set.union(*samp_neighs))\n",
    "print(unique_nodes_list)\n",
    "# node_id: rownum pairs\n",
    "unique_nodes = {n:i for i,n in enumerate(unique_nodes_list)}\n",
    "# mask: num_nodes * num_all_neighbors tensor\n",
    "mask = torch.zeros(len(samp_neighs), len(unique_nodes))\n",
    "# colunm: rownum of all sampled neighbors\n",
    "column_indices = [unique_nodes[n] for samp_neigh in samp_neighs for n in samp_neigh]\n",
    "print(column_indices)\n",
    "# row: len(samp_neighs[i]) times node i \n",
    "row_indices = [i for i in range(len(samp_neighs)) for j in range(len(samp_neighs[i]))]\n",
    "print(row_indices)\n",
    "# mask: adj matrix after sampling\n",
    "mask[row_indices, column_indices] = 1\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "num_neigh = mask.sum(1, keepdim=True)\n",
    "mask = mask.div(num_neigh)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]])\n",
      "tensor([[2.],\n",
      "        [3.],\n",
      "        [4.]])\n",
      "tensor([[2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "# features after sampling\n",
    "features = torch.tensor([[1.], [2.], [3.], [4.]])\n",
    "print(features)\n",
    "embed_features = features[torch.tensor(unique_nodes_list)]\n",
    "print(embed_features)\n",
    "# mean aggregation\n",
    "to_feats = mask.mm(embed_features)\n",
    "print(to_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes a node's using 'convolutional' GraphSage approach\n",
    "    \"\"\"\n",
    "    def __init__(self, features, feature_dim, \n",
    "            embed_dim, adj_lists, aggregator,\n",
    "            num_sample=10,\n",
    "            base_model=None, gcn=False, cuda=False, \n",
    "            feature_transform=False): \n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.features = features # all features\n",
    "        self.feat_dim = feature_dim\n",
    "        self.adj_lists = adj_lists # all adj lists\n",
    "        self.aggregator = aggregator\n",
    "        self.num_sample = num_sample\n",
    "        if base_model != None:\n",
    "            self.base_model = base_model\n",
    "\n",
    "        self.gcn = gcn\n",
    "        self.embed_dim = embed_dim\n",
    "        self.cuda = cuda\n",
    "        self.aggregator.cuda = cuda\n",
    "        self.weight = nn.Parameter(\n",
    "                torch.FloatTensor(embed_dim, self.feat_dim if self.gcn else 2 * self.feat_dim))\n",
    "        init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, nodes):\n",
    "        \"\"\"\n",
    "        Generates embeddings for a batch of nodes.\n",
    "\n",
    "        nodes     -- list of nodes\n",
    "        \"\"\"\n",
    "        # aggregation: batch of nodes\n",
    "        neigh_feats = self.aggregator.forward(nodes, [self.adj_lists[int(node)] for node in nodes], \n",
    "                self.num_sample)\n",
    "        if not self.gcn:\n",
    "            if self.cuda:\n",
    "                self_feats = self.features(torch.LongTensor(nodes).cuda())\n",
    "            else:\n",
    "                self_feats = self.features(torch.LongTensor(nodes))\n",
    "            combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
    "        else:\n",
    "            combined = neigh_feats\n",
    "        # one layer encoding: embed_dim * num_batch_nodes\n",
    "        combined = F.relu(self.weight.mm(combined.t()))\n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"graphsage model\"\"\"\n",
    "class SupervisedGraphSage(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, enc):\n",
    "        super(SupervisedGraphSage, self).__init__()\n",
    "        self.enc = enc\n",
    "        self.xent = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, enc.embed_dim))\n",
    "        init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, nodes):\n",
    "        embeds = self.enc(nodes)\n",
    "        scores = self.weight.mm(embeds)\n",
    "        return scores.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model\"\"\"\n",
    "# random data\n",
    "feat_data = torch.rand([2708, 1433])\n",
    "adj_lists = [set(random.sample(range(2708), 15)) for _ in range(2708)]\n",
    "# input\n",
    "features = nn.Embedding(2708, 1433)\n",
    "features.weight = nn.Parameter(torch.FloatTensor(feat_data), requires_grad=False)\n",
    "# layer 1\n",
    "agg1 = MeanAggregator(features)\n",
    "enc1 = Encoder(features, 1433, 128, adj_lists, agg1, gcn=True)\n",
    "# layer 2\n",
    "agg2 = MeanAggregator(lambda nodes : enc1(nodes).t())\n",
    "enc2 = Encoder(lambda nodes : enc1(nodes).t(), enc1.embed_dim, 128, adj_lists, agg2,\n",
    "        base_model=enc1, gcn=True)\n",
    "# model\n",
    "graphsage = SupervisedGraphSage(7, enc2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
